{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Practical 05: Robot Control</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.linalg as linalg\n",
    "import pickle\n",
    "\n",
    "from Practical05_Support.Robot import *\n",
    "from Practical05_Support.Helper import *\n",
    "from Practical05_Support.Renderer import Renderer as PenguinPiRenderer\n",
    "from Practical05_Support.Renderer1D import RobotRenderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See docstring for functions in support scripts**: If you want to know what a function does, just click somewhere within the parentheses that enclose the arguments and hit SHIFT+TAB. If there's a + button at the top of the popup tooltip, this means the documentation spans a few lines, click it to show the full docstring, then scroll up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PID Control - 1D Linear System\n",
    "\n",
    "Recall our 1D robot \n",
    "\n",
    "<img src=\"https://i.postimg.cc/k4M3B22Y/1DRobot.png\" width=\"400\" height=\"400\" align=\"center\">\n",
    "\n",
    "We want to implement a controller that generates the signal $\\mathbf{u}_t$ required to bring the robot to a desired state $\\mathbf{x}_d$\n",
    "\n",
    "We first define our robot in State-Space Form:\n",
    "\n",
    "<center> $\\mathbf{x}_{t+1} = A\\mathbf{x}_t + B\\mathbf{u}_t$ </center>\n",
    "<center> $\\mathbf{y}_{t} = C\\mathbf{x}_t$, </center>\n",
    "\n",
    "where $A$ corresponds to the state matrix, $B$ defines the input or control matrix and $C$ corresponds to the output matrix. Our robot will be represented by the Python class ``Robot1D``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our PID Controller\n",
    "\n",
    "Let us now define our PID controller. Recall the formulation of a PID controller in the discrete domain:\n",
    "\n",
    "<center>$\\mathbf{u}_t = K_p \\mathbf{e}_t + K_i \\sum_{k = 0}^t \\mathbf{e}_k \\Delta t + K_d \\frac{\\mathbf{e}_t - \\mathbf{e}_{t-1}}{\\Delta t}$, where</center>\n",
    "\n",
    "- $K_p, K_i, K_d$ are the proportional, integral and derivative gains\n",
    "- $\\mathbf{e}_t$ is the error at time $t$. In our case $\\mathbf{e}_t = \\mathbf{x}_d - \\mathbf{x}_t$\n",
    "- $\\Delta t$ is the rate at which the PID controller is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PID(object):\n",
    "    \n",
    "    \"\"\"A simple PID controller.\"\"\"\n",
    "\n",
    "    def __init__(self, system=None, desired_state=None, K_p=0, \n",
    "                 K_i=0, K_d=0, update_rate=0.05):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize a new PID controller.\n",
    "        :param system: The robot system to controlled\n",
    "        :param desired_state: The goal state that the PID will try to achieve for the robotic system\n",
    "        :param K_p: The value for the proportional gain K_p\n",
    "        :param K_i: The value for the integral gain K_i\n",
    "        :param K_d: The value for the derivative gain K_d\n",
    "        :param update_rate: Rate at which the PID controller is updated. \n",
    "        \"\"\"\n",
    "        self.system = system\n",
    "        self.set_point = desired_state\n",
    "        self.K_p = K_p\n",
    "        self.K_i = K_i\n",
    "        self.K_d = K_d\n",
    "        self.update_rate = update_rate\n",
    "        \n",
    "        # Last observed error between desired state (self.set_point) and the current state of the system\n",
    "        self.last_error = self.system.get_error(self.set_point)\n",
    "        \n",
    "        # Accumulator for integral term\n",
    "        self.integral = 0\n",
    "        \n",
    "        # Last time the controller was called\n",
    "        self.last_time = 0\n",
    "        \n",
    "        # Last control command provided to the system\n",
    "        self.last_control = 0\n",
    "        \n",
    "    def compute_control(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        This method computes the next control signal u_t so as to reduce the error\n",
    "        between the robot's current state and the desired state (self.set_point)\n",
    "        \"\"\"\n",
    "        \n",
    "        delta_time = self.update_rate\n",
    "        \n",
    "        # Compute error\n",
    "        error_t = self.system.get_error(self.set_point)\n",
    "        \n",
    "        # Compute integral and derivative terms\n",
    "        derivative = (error_t - self.last_error) / delta_time\n",
    "        self.integral += error_t * delta_time\n",
    "        \n",
    "        # Compute new control\n",
    "        new_control = self.K_p * error_t + self.K_i * self.integral + self.K_d * derivative\n",
    "        \n",
    "        # Update self.last_error, self.last_time and self.last_control signal with new values\n",
    "        self.last_error = error_t\n",
    "        self.last_time += self.update_rate\n",
    "        self.last_control = new_control\n",
    "                \n",
    "        return new_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Controller\n",
    "\n",
    "Let us now test our controller. We consider the following values in our current test case:\n",
    "- The robot initial state is $\\mathbf{x}_0 = (10, 0)$. The desired states is $\\mathbf{x}_d = (50, 0)$\n",
    "- The PID gains are set to $K_p=0.2, K_i=0, K_d=0.001$\n",
    "- Our control loop runs for 15 frames (controlled by the variable total_frames) with $dt=0.01$ (controlled by the variable update_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state, input and output matrices\n",
    "A = np.array([[1, 0], [1, 0]]) # 2D robot but only has control in the x-axis\n",
    "B = np.array([[0.5],[0]])\n",
    "C = np.array([1, 0])\n",
    "\n",
    "# Create a robot and define desired state\n",
    "initial_state = np.array([[10],[0]])\n",
    "bot = Robot1D(A=A, B=B, C=C, initial_state=initial_state)\n",
    "desired_x = np.array([[50],[0]])\n",
    "\n",
    "# Visualization parameters\n",
    "u, sim_time, error, robot_state = np.array([[0],[0]]), np.array([0]), bot.get_error(desired_x), bot.get_output()\n",
    "total_frames = 50\n",
    "update_rate = 0.01\n",
    "\n",
    "# Create a PID controller\n",
    "pid = PID(system=bot, desired_state=desired_x, K_p=0.2, K_i=0, K_d=0.001, update_rate=update_rate)\n",
    "\n",
    "# This is our control loop. Currently we call our controller for 1 second\n",
    "for curr_frame in range(1, total_frames, 1):\n",
    "    \n",
    "    # Call controller to get new signal u_t\n",
    "    u_t = pid.compute_control()\n",
    "    \n",
    "    # Apply control to robot\n",
    "    bot.drive(u_t)\n",
    "\n",
    "    # Save values for plotting\n",
    "    sim_time = np.hstack( (sim_time, update_rate*int(curr_frame)))\n",
    "    error = np.hstack((error, bot.get_error(desired_x)))\n",
    "    u = np.hstack((u, u_t))\n",
    "    robot_state = np.hstack((robot_state, bot.get_output()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the Resulting Trajectories\n",
    "\n",
    "Let us now plot the changes observed in error (right-bottom), control signal (right-top), and robot's state (left) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define renderer and start animation\n",
    "rend = RobotRenderer.Instance()\n",
    "rend.initialize(robot_state, u, error, sim_time, desired_x, dt_render=update_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PID Control - Differential Drive Vehicle\n",
    "\n",
    "Recall the kinematic model of our PenguinPi robot:\n",
    "\n",
    "<img src=\"https://i.postimg.cc/NMNhTQTs/Penguin-Pi-Model.png\" width=\"400\" height=\"400\" align=\"center\">\n",
    "\n",
    "In this model, the state is defined by a 3D vector ($x, y, \\theta)$ and the control input corresponds to the linear and angular velocities $(v, \\omega)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Move to Goal Controller\n",
    "\n",
    "Consider the problem of moving the PenguinPi to a goal point $(x_g, y_g)$. How can we solve this control problem?\n",
    "\n",
    "Let us define 2 proportional controllers:\n",
    "- One controller with gain $K_{pw}$ that will turn the robot toward the goal. This controller determines the angular velocity $\\omega_k$ according to\n",
    "\n",
    "<center> $\\omega_k = K_{pw} (\\theta_g - \\theta_r)$, </center> \n",
    "\n",
    "where $\\theta_g$ corresponds to the angle to the goal relative to the heading of the robot and $\\theta_r$ is the heading of the robot at time $k$.\n",
    "\n",
    "- One controller with gain $K_{pv}$ that will keep moving the robot forward until it reaches the goal. This controller determines the linear velocity $v_k$ according to\n",
    "\n",
    "<center> $v_k = K_{pv}\\sqrt{(y_g-y_k)^2+(x_g-x_k)^2}$ </center> \n",
    "\n",
    "We have combined these 2 controllers into a single class called ``MoveToGoalController``. Two helper functions ``get_distance_robot_to_goal(.)`` and ``get_angle_robot_to_goal(.)`` have been defined to compute $(\\theta_g - \\theta_r)$ and $\\sqrt{(y_g-y_k)^2+(x_g-x_k)^2}$ respectively.\n",
    "\n",
    "\n",
    "#### TODO: \n",
    "- Compute both $\\omega_k$ and $v_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveToGoalController(object):\n",
    "    \n",
    "    \"\"\"A simple move to goal proportional controller\"\"\"\n",
    "\n",
    "    def __init__(self, robot=None, K_pw=0, K_pv=0, ):\n",
    "        \"\"\"\n",
    "        Initialize a new move to goal proportional controller\n",
    "        :param robot: The robotic system to controlled\n",
    "        :param K_w: The proportional gain for the angular velocity\n",
    "        :param K_v: The proportional gain for the linear velocity\n",
    "        \"\"\"\n",
    "        self.robot = robot\n",
    "        self.K_pw = K_pw\n",
    "        self.K_pv = K_pv\n",
    "        \n",
    "    def run(self, goal_position=np.zeros(2), threshold=0.1, delta_time=0.01, max_iteration = 1000):\n",
    "        \"\"\"\n",
    "        Run control loop until the robot reaches the goal_position\n",
    "        :param goal_position: Desired goal position\n",
    "        :param threshold: Value used to determine whether robot has reached \n",
    "                          the goal location\n",
    "        \"\"\"\n",
    "        states = []\n",
    "        controls = []\n",
    "        initial_state = self.robot.get_state()\n",
    "        \n",
    "        distance_to_goal = get_distance_robot_to_goal(initial_state, goal_position)\n",
    "        desired_heading = get_angle_robot_to_goal(initial_state, goal_position)\n",
    "                \n",
    "        states.append(initial_state)\n",
    "        \n",
    "        for i in range(max_iteration):\n",
    "            \n",
    "            #TODO: Compute control input -----------------------------------------------------\n",
    "            v_k = 0\n",
    "            w_k = 0\n",
    "            #ENDTODO --------------------------------------------------------------------------\n",
    "            \n",
    "            # Apply control to robot\n",
    "            self.robot.drive(v_k, w_k, delta_time)\n",
    "            new_state = self.robot.get_state()\n",
    "            \n",
    "            # Keep track of variables for plotting\n",
    "            controls.append([v_k, w_k])\n",
    "            states.append(new_state)\n",
    "                        \n",
    "            # Update distance and desired heading\n",
    "            distance_to_goal = get_distance_robot_to_goal(new_state, goal_position)\n",
    "            desired_heading = get_angle_robot_to_goal(new_state, goal_position)\n",
    "\n",
    "            if distance_to_goal < threshold:\n",
    "                break\n",
    "\n",
    "        if len(states) == (max_iteration + 1):\n",
    "            print(f\"Did not the destination (distance to goal is larger than {threshold}), terminated after {max_iteration} iterations.\")\n",
    "        else:\n",
    "            print(f\"Successfully reach the destination (distance to goal is less than {threshold}), terminated after {len(states) - 1} iterations.\")\n",
    "        \n",
    "        return states, controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Controller\n",
    "\n",
    "Let us now visualise how our PenguinPi robot moves toward a goal position using the control signals computed by our ``MoveToGoalController``\n",
    "\n",
    "We consider the following values in our current test case:\n",
    "- The robot initial state is $\\mathbf{x}_0 = (-1.5, -1.5, \\frac{\\pi}{3})$. The desired states is $\\mathbf{x}_d = (1.0, 1.0)$.\n",
    "- The proportional gains are set to $K_{pw}=5, K_{pv}=2$\n",
    "- Our control loop runs until $\\sqrt{(y_g-y_k)^2+(x_g-x_k)^2} > 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define robot, desired goal and delta time\n",
    "bot = PenguinPi(init_state=np.array([-1.5, -1.5, np.pi/3]))\n",
    "desired_goal = np.array([1.0, 1.0]) # target x, target y\n",
    "delta_t = 0.01\n",
    "\n",
    "# Instantiate controller and compute sequence of control signals\n",
    "controller = MoveToGoalController(bot, K_pw=5, K_pv=2)\n",
    "robot_states, robot_controls = controller.run(goal_position=desired_goal, threshold=0.01, delta_time=delta_t)\n",
    "\n",
    "# Define variables for animation\n",
    "array_states = np.array(robot_states)\n",
    "array_controls = np.array(robot_controls)\n",
    "\n",
    "# Define renderer and start animation\n",
    "rend = PenguinPiRenderer.Instance()\n",
    "rend.initialize(array_states, array_controls, target_pose=desired_goal, dt_data=delta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LQR - Discrete Time Infinite Horizon\n",
    "\n",
    "Given a linear system with equations:\n",
    "\n",
    "<center> $\\mathbf{x}_{t+1} = A\\mathbf{x}_t + B\\mathbf{u}_t$ </center>\n",
    "<center> $\\mathbf{y}_{t} = C\\mathbf{x}_t$, </center>\n",
    "\n",
    "where $A$ corresponds to the state matrix, $B$ defines the input or control matrix and $C$ corresponds to the output matrix.\n",
    "\n",
    "We wan to find $\\mathbf{u}$ so as to minimize the cost function\n",
    "\n",
    "<center>$J = \\sum_{t=0}^{\\infty} ((\\mathbf{x}_t-\\mathbf{x}_g)^TQ(\\mathbf{x}_t-\\mathbf{x}_g) + \\mathbf{u}_t^TR\\mathbf{u})$, </center> \n",
    "\n",
    "where $Q$ defines the state cost and $R$ corresponds to the control cost.\n",
    "\n",
    "To do so, we want to implement a **LQR Infinite Horizon Controller** with gain  \n",
    "<center> $K = (R+B^TPB)^{-1}(B^TPA)$ </center>\n",
    "\n",
    "**TODO:**\n",
    "- Complete the definition of the controller's gain K. You can use the function ``linalg.inv(.)`` to compute the inverse of a matrix\n",
    "- Keep in mind that $P$ is defined by the class attribute ``self.P``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteInfiniteLQR(object):\n",
    "    \n",
    "    \"\"\"A simple LQR Infinite Horizon controller.\"\"\"\n",
    "\n",
    "    def __init__(self, Q=np.eye(2), R=0.3):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize a new LQR controller.\n",
    "        :param Q: State cost\n",
    "        :param R: Control cost\n",
    "        \"\"\"\n",
    "        \n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "        \n",
    "        # Controller gain to be defined once LQR function is solved\n",
    "        self.K = np.zeros(2)\n",
    "        self.P = np.eye(2)\n",
    "                \n",
    "    def solve(self, system):\n",
    "        \"\"\"\n",
    "        Compute controller gain for a given system\n",
    "        :param system: Linear system for which a control law needs to be\n",
    "                       computed\n",
    "        \"\"\"\n",
    "        A = system.A\n",
    "        B = system.B\n",
    "        \n",
    "        # Solve Riccati Equation\n",
    "        self.P = linalg.solve_discrete_are(A, B, self.Q, self.R)\n",
    "                \n",
    "        #TODO: Compute the controller's gain ----------------------------------------------\n",
    "        self.K = np.zeros([1,2])\n",
    "        #ENDTODO --------------------------------------------------------------------------\n",
    "        \n",
    "    def get_gain(self):\n",
    "        \"\"\"\n",
    "        Get access to controller gain\n",
    "        \"\"\"\n",
    "        return self.K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Controller\n",
    "\n",
    "Let us now take a look at the state and control trajectories that can obtained using our LQR implementation. Keep in mind that the optimal controller is defined as\n",
    "\n",
    "<center>$\\mathbf{u_t} = -K(\\mathbf{x_t} - \\mathbf{x_g})$, </center>\n",
    "\n",
    "where $\\mathbf{x_g}$ corresponds to the desired state.\n",
    "\n",
    "We consider the same test case used with our PID controller:\n",
    "- The robot initial state is $\\mathbf{x}_0 = (10, 0)$. The desired states is $\\mathbf{x}_d = (50, 0)$\n",
    "- Our control loop for 25 time steps with the update rate defined by the variable update_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of our 1D robot system\n",
    "A = np.array([[1, 0], [1, 0]])\n",
    "B = np.array([[0.5],[0]])\n",
    "C = np.array([1, 0])\n",
    "\n",
    "bot = Robot1D(A=A, B=B, C=C, initial_state=np.array([[10], [0]]))\n",
    "\n",
    "# Define the state and control costs\n",
    "Q = np.array([[5,0],[0,0]])\n",
    "R = 20\n",
    "\n",
    "# Create an instace of our controller and solve the LQR problem\n",
    "lqr = DiscreteInfiniteLQR(Q=Q, R=R)\n",
    "lqr.solve(bot)\n",
    "\n",
    "# Define desired state\n",
    "desired_x = np.array([[50],[0]])\n",
    "\n",
    "# Visualization parameters\n",
    "u_list, sim_time = np.array([[0]]), np.array([0])\n",
    "\n",
    "error = bot.get_error(desired_x)\n",
    "y_list = bot.get_output()\n",
    "update_rate = 0.01\n",
    "total_frames = 25\n",
    "\n",
    "# This is our control loop. \n",
    "for curr_frame in range(1, total_frames, 1):\n",
    "    \n",
    "    # Get current state of the system\n",
    "    x_t = bot.get_state()\n",
    "    # Get output \n",
    "    y_t = bot.get_output()\n",
    "    \n",
    "    # Determine and apply control\n",
    "    u_t = np.array(-lqr.K @ (x_t - desired_x))\n",
    "    bot.drive(u_t)\n",
    "    \n",
    "    # Keep track of variable for plotting\n",
    "    sim_time = np.hstack( (sim_time, update_rate*curr_frame))\n",
    "    u_list =np.hstack((u_list, u_t))\n",
    "    y_list = np.hstack((y_list,y_t)) \n",
    "    error = np.hstack((error, bot.get_error(desired_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the Resulting Trajectories\n",
    "\n",
    "Let us now plot the changes observed in error (right-bottom), control signal (right-top), and robot's state (left) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define renderer and start animation\n",
    "rend = RobotRenderer.Instance()\n",
    "rend.initialize(y_list, u_list, error, sim_time, desired_x, dt_render=update_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
