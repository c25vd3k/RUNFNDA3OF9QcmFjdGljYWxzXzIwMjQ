{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "28f71426-ad71-4ff1-837b-4d6a95a0909b",
    "deepnote_cell_height": 108.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"30\" >Practical 06 - Robotic Vision</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-c5278e80-d3d7-4dda-8164-2fefe508a626",
    "deepnote_cell_height": 228.375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<tr>\n",
    "<td><div align=\"left\"><font size=\"10\" >4. Training a fully connected neural network for digit classification</font></div></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-149e59e6-1638-423e-8499-83295a46ba4a",
    "deepnote_cell_height": 100.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Import all the packages required. \n",
    "If you are using GPU, change `FLAG_GPU` to `True` (we are not doing heavy computation in this notebook so `FLAG_GPU` is not that important, and I don't have a GPU to test things so ... if you want it to work with GPU you have to look into how to do that yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-45c43b68-7f7d-4ad3-8941-1effcad15791",
    "deepnote_cell_height": 508,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4776,
    "execution_start": 1660625083125,
    "source_hash": "2af7391b"
   },
   "outputs": [],
   "source": [
    "# Change this flag if using a GPU\n",
    "FLAG_GPU = False\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import time for timekeeping\n",
    "import time\n",
    "\n",
    "# Pytorch (Our Deep Learning Framework)\n",
    "import torch\n",
    "\n",
    "# Torch Data Loader (this will be helful to load image)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# datasets have mnist if using coustom images import io from skimage\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "# stores different optimizors like SGD\n",
    "import torch.optim as optim\n",
    "\n",
    "# Some torch functions that are used multiple times\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-968a68c2-d87a-4912-904a-c6b028c07eac",
    "deepnote_cell_height": 404.515625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Let's Define a Multi Layer Perceptron \"__ init __ \" function\n",
    "* Any network has an `* __ init __ *` function that initializes all the layers of the NN that require learnable parameters.\n",
    "* A MLP is a stack of fully connected layers. In this example we use three fully connected layers named :`fc0`, `fc1` and `fc2`.\n",
    "* Note that each fully connected layer has a number of input neurons that connect to a number of output neurons. \n",
    "* These input and output dimensions are specified in the fc layer initialization.\n",
    "* If a fully connected layer connects to another, its output size = input size of the fully connected layer that follows.\n",
    "* The number of paramenters in any fully connected layer is #Input x #Output (and 1 bias per output).\n",
    "\n",
    "## How do we write a forward function?\n",
    "* `torch.flatten(x, start_dim = dim)` converts an image-like entity to a vector.\n",
    "* Remeber that you need activations after every fully connected layer. In this case we use ReLu. \n",
    "* Notice the `log_softmax` layer at the end. This is a softmax activation function followed by log function as the name suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-7a934535-addd-4449-b97a-16d03693ce41",
    "deepnote_cell_height": 508,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1660625091268,
    "source_hash": "f708128f"
   },
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        # First fully connected layer's input image is 28x28 = 784 dim.\n",
    "        self.fc0 = nn.Linear(784, 256) # nparam = 784*256 = 38400\n",
    "        \n",
    "        # Two more fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flattens the image-like structure into vectors\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # fully connected layers with activations\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # Outputs are log(p) so softmax followed by log.\n",
    "        #return(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-5e982cbf-92fc-4e76-8f18-d8eef3b39459",
    "deepnote_cell_height": 144.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Initializing an instance of the defined network here.\n",
    "* Note that putting a network to GPU is as simple as writing .cuda() at the end of the instance. In this notebook the code inside the command `if FLAG_GPU` shows all the modifications you need to run your code on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-408268ad-9e1b-4bf8-aa45-34f0902ce969",
    "deepnote_cell_height": 295.9375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1660625094008,
    "source_hash": "cede7644"
   },
   "outputs": [],
   "source": [
    "net = MLPNet()\n",
    "if FLAG_GPU:\n",
    "    print('Using GPU:', torch.cuda.get_device_name(0))\n",
    "    net.cuda()\n",
    "    print(net)\n",
    "else:\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-e46b1a8b-c94d-4ce0-8d33-567cc36a1158",
    "deepnote_cell_height": 243.34375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Dataloaders and Transforms.\n",
    "* `dataset.MNIST` in pytorch implements the functionality to download and process MNIST data.\n",
    "* dataloader function usually allows for loading parts of training and test data in minibatches.\n",
    "* It can use some simple transformations implemented in class transforms that assists training. For example normalizing, resizing or cropping images.\n",
    "* The functionality of the dataset, transform and dataloader classes are usually added to suit new data and training proceedure related to the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-42404514-d846-4aac-aecf-140f27d12a0d",
    "deepnote_cell_height": 292,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 137,
    "execution_start": 1660625098076,
    "source_hash": "e6bc69c9"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Training dataset and training loader.\n",
    "trainset = datasets.MNIST(root='./Practical06_Support/data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# Test dataset and loader.\n",
    "testset = datasets.MNIST(root='./Practical06_Support/data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-b616d6c0-ec5c-457d-9d14-95ddd5bc78df",
    "deepnote_cell_height": 187.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Here we see sample usage of loading some MNIST training data.\n",
    "* What does our training minibatch look like?\n",
    "* At times simple visualization and print statements allow for understanding/debugging effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-e6a593e8-08d3-4ec7-bf55-0bc38627551c",
    "deepnote_cell_height": 721.125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     204
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 422,
    "execution_start": 1660625102960,
    "source_hash": "3aa1cdf3"
   },
   "outputs": [],
   "source": [
    "def imshow(img, l):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    print('Labels were:')\n",
    "    print(l.reshape(-1,8).numpy())\n",
    "\n",
    "# Load sample data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print('shape of images', images.shape)\n",
    "\n",
    "# display batch\n",
    "imshow(utils.make_grid(images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-29ab0013-1579-4fff-a13b-d8afd7838353",
    "deepnote_cell_height": 392.515625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Loss function for learning.\n",
    "* NLLLoss: The abbrivation NLL stands for Negetive log likelihood. It is however a bit of misnomer as the log is not included in the loss itself but was part of the network defination above. \n",
    "* NOTE: When you want to get the probability/likelihood of an image being of a perticular class you need to remove the log from the forward function and use simple softmax activation at test time. Alternatively simply use `exp` function from torch to invert log and leave the forward function as it is. \n",
    "\n",
    "## Optimizer\n",
    "* pytorch has various optimization rutines (beyond SGD) pre-implemented.\n",
    "* class `optim` will take care of backpropogation with these different optimizations for learning as long as the network definition with appropriate forward function is written correctly.\n",
    "* Here we just use SGD with learning rate 0.001 and momentum 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-03637307-702a-498b-b1ac-9105915b3b68",
    "deepnote_cell_height": 130,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1660625109377,
    "source_hash": "2bfdeed4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "if FLAG_GPU:\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-628e7fed-d6b5-4a7f-a557-1fa87635aa69",
    "deepnote_cell_height": 641.25,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## This cell of the notebook is training the network.\n",
    "\n",
    "* The first for loop goes through the entire data 5 times (We run 5 epochs for our training).\n",
    "* The simple steps for training a NN with pytorch are:\n",
    "    * Load data in minibatches.\n",
    "    * Set gradients for all the network parameters to zero (dont forget this)\n",
    "    * Pass data to the NN using a `net.forward()` to compute layer by layer output.\n",
    "        * Intermediate outputs can be returned as extra variables in forward function.\n",
    "    * Compute the loss from the output (remember it is defined above).\n",
    "    * Use `loss.backward()` to compute all the gradients by appropriately applying chain rule! \n",
    "        * It actually knows how to differentiate things!!!\n",
    "    * Use `optimizer.step()` to update the weights.\n",
    "    \n",
    "## At the end of every epoch usually we check if NN generalizes.\n",
    "* Generalization is critical in learning.\n",
    "* We evaluate the performance of our NN on new data, for which the NN loss was not minimized.\n",
    "* The `torch.no_grad()` command forces the following code to not keep track of the gradients as for testing we don't need them.\n",
    "* As no gradients are maintained, the code runs faster!\n",
    "* It is very good practice to make use of `no_grad` function to ensure that we dont accidently minimize loss on the data we are testing the performance on.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-ee0ed247-0528-4c2c-8923-82a6ed16eae4",
    "deepnote_cell_height": 1848,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 152616,
    "execution_start": 1660625115942,
    "source_hash": "51196a4a"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Simply for time keeping\n",
    "    start_time = time.time()\n",
    "    # Loop over all training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    " \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        if FLAG_GPU:\n",
    "            outputs = net(inputs.cuda())\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "        else:\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute Gradients\n",
    "        loss.backward()\n",
    "        # BackProp\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        # endif\n",
    "    # end for over minibatches epoch finishes\n",
    "    end_time = time.time()\n",
    "\n",
    "    # test the network every epoch on test example\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Test after the epoch finishes (no gradient computation needed)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            # load images and labels\n",
    "            images, labels = data\n",
    "\n",
    "            if FLAG_GPU:\n",
    "                outputs = net(images.cuda())\n",
    "                # note here we take the max of all probability\n",
    "                _, predicted = torch.max(outputs.cpu(), 1)\n",
    "            else:\n",
    "                outputs = net(images)\n",
    "                # note here we take the max of all probability\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "      #end for\n",
    "    #end with\n",
    "    print('Epoch', epoch+1, 'took', end_time-start_time, 'seconds')\n",
    "    print('Accuracy of the network after', epoch+1, 'epochs is' , 100*correct/total)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "14d89f36b9a24be1aded61558cedce18",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Using the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "28f64cf94c884cb5a7e2f745eb95f808",
    "deepnote_cell_height": 465.375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     249
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 212,
    "execution_start": 1660625810093,
    "source_hash": "7775f7be",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image = images[3]\n",
    "plt.imshow(np.array(test_image).transpose((1,2,0))[:, :, 0])\n",
    "print(f'Labels were: {labels[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "allow_embed": false,
    "cell_id": "ecf74c54a9b346229087ce4ac40158bb",
    "deepnote_cell_height": 302.375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     20.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1660625825589,
    "source_hash": "75f4d8a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = images[3]\n",
    "# run the forward pass\n",
    "with torch.no_grad():\n",
    "    if FLAG_GPU:\n",
    "        outputs = net(input.cuda())\n",
    "    else:\n",
    "        outputs = net(input)\n",
    "        \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(f\"The network predicted: {predicted.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "070e3a6649b94789befde2151a40effb",
    "deepnote_cell_height": 159.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Flux Question 4\n",
    "Looking at the difference between more traditional computer vision and more recent machine learning approaches. What is similar / what is different?\n",
    "\n",
    "Particularly for training computer vision models, what are critical components for these techniques?\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "7909e992-03c1-4655-b72b-e0123a5727ee",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
