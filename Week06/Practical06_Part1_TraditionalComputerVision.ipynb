{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "52008a78-3b01-4272-b87c-00eb4b594939",
    "deepnote_cell_height": 108.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"30\" >Practical 06 - Robotic Vision</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-59f803d7-1e3e-4d5d-9b05-0af04999311d",
    "deepnote_cell_height": 151.578125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<tr>\n",
    "<td><div align=\"left\"><font size=\"11\" >1. Images and Pixels</font></div></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-63538835-44f7-453a-9e80-3e39e877af22",
    "deepnote_cell_height": 155.953125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We need to import some modules. We will use the standard `numpy` package to help us with linear algebraic operations on matrices and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-7d8ae7f2-1b0a-4d38-809e-66a4592df9d6",
    "deepnote_cell_height": 379.375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     1
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1202,
    "execution_start": 1660623918539,
    "source_hash": "bb06ff68"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os.path\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-8116c0f5-1779-4325-be2f-b0cf6ecff2fa",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's define some helper functions to read, ``iread(relative_path_to_image)``, and display an image ``idisp(image_array)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-318eb40d-c63f-4ed9-bcfa-fb81a4eed2d5",
    "code_folding": [
     11
    ],
    "deepnote_cell_height": 981,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1660623919748,
    "source_hash": "6d0bf5e3"
   },
   "outputs": [],
   "source": [
    "# read an image with colors in RGB order for matplotlib\n",
    "\n",
    "def iread(filename):\n",
    "    \"\"\"\n",
    "    This function reads an image. Only images in the \"images\" folder are considered\n",
    "\n",
    "    :param image: str with name of image to be read. \n",
    "    :return: a numpy array of size [image_height, image_width] where each [i,j] corresponds to a pixel in the image.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(cv2.imread(os.path.join('Practical06_Support/images', filename)), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# read an image with colors in RGB order for matplotlib\n",
    "def iread_color(filename):\n",
    "    \"\"\"\n",
    "    This function reads an image. Only images in the \"images\" folder are considered\n",
    "\n",
    "    :param image: str with name of image to be read. \n",
    "    :return: a numpy array of size [image_height, image_width] where each [i,j] corresponds to a pixel in the image.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(cv2.imread(os.path.join('Practical06_Support/images', filename)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def idisp(image, cmap = 'gray', height = None):\n",
    "    \"\"\"\n",
    "    Displaying interactive image.\n",
    "    \"\"\"\n",
    "    labels = dict(x=\"u (pixels)\", y=\"v (pixels)\")\n",
    "    if height is None: \n",
    "        fig = px.imshow(image,color_continuous_scale=cmap, labels = labels)\n",
    "    else:\n",
    "        fig = px.imshow(image,color_continuous_scale=cmap, labels = labels, height = height)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-7498208f-2e69-40d5-bf02-bcc4643b7ec3",
    "deepnote_cell_height": 111.171875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We will start by loading an image\n",
    "\n",
    "We will use a convenience function to read the image from a PNG format file.  We can load files of different types (with different extensions), eg. `.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-d26b332d-802d-42e3-a3d4-30798573775d",
    "deepnote_cell_height": 130.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 45,
    "execution_start": 1660623919763,
    "source_hash": "1833bca8"
   },
   "outputs": [],
   "source": [
    "image = iread('monalisa.png')\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-6baf55ff-0b5b-42c1-8f83-14b29efcc984",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "and `image` is a numpy array (a python style matrix) with dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-73102629-7b51-40c9-96ce-7e73fdf0aaec",
    "deepnote_cell_height": 112.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1660623919808,
    "source_hash": "4e38d542"
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-4f8f5c4e-f0be-408b-b68c-96417ba8fee7",
    "deepnote_cell_height": 88.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "which we see has 700 rows and 677 columns.\n",
    "\n",
    "The data itself is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-955db728-4256-4570-93b0-efb4c80ea281",
    "deepnote_cell_height": 227.3125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     135.3125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1660623919820,
    "source_hash": "eb852f86"
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-bea588b5-71f1-4459-bb9f-615fb3fa549d",
    "deepnote_cell_height": 88.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "is simply a big table of 8-bit integers which represent brightness of each pixel as a number between 0 (black) and 1 (white).\n",
    "\n",
    "We can display it as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-e7365523-c6f6-494b-bfdb-19a036ec83c3",
    "deepnote_cell_height": 468,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     376
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1081,
    "execution_start": 1660623919832,
    "source_hash": "ad1ed3a5"
   },
   "outputs": [],
   "source": [
    "idisp(image, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-aa8ee1f6-41d1-4c4b-bd6a-2f88f3697f2c",
    "deepnote_cell_height": 111.171875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**The notebook image view is interactive. If you drift your cursor over the image it displays the pixel coordinate and the grey value of the pixel.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-f9267357-9cd6-46e1-8f8f-3889f5317258",
    "deepnote_cell_height": 112.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 779,
    "execution_start": 1660623920135,
    "source_hash": "a3900c4d"
   },
   "outputs": [],
   "source": [
    "image[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-96b30e18-948f-4567-94f0-13b8411f794f",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Common indexing error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-8b9959d9-c727-4557-82f9-61b745b9a1d1",
    "deepnote_cell_height": 139.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1660623920156,
    "source_hash": "35364823"
   },
   "outputs": [],
   "source": [
    "image[700,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-dadd0746-53b2-4579-aa71-8d7506a85540",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now index is not out of bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-1eb5e37b-970b-4d5d-ac09-e8b996eb104d",
    "deepnote_cell_height": 112.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.1875
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 6,
    "execution_start": 1660617217162,
    "source_hash": "63d0b80e"
   },
   "outputs": [],
   "source": [
    "image[677,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-0377d492-3cfc-4028-8630-7778015f8081",
    "deepnote_cell_height": 108.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"18\">2. Basic Image Processing</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-aa982ca6-c621-4894-89b2-a9b4a32096cb",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's increase the image **brightness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00023-1cdc3ecd-3586-470f-8561-63f61b0f6c2b",
    "deepnote_cell_height": 504,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     376
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 297,
    "execution_start": 1660617219658,
    "source_hash": "383552c4"
   },
   "outputs": [],
   "source": [
    "added = 120\n",
    "image2 = image+added \n",
    "idisp(image2,height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-d790b433-bd9e-4ecf-9abe-c92391822cc3",
    "deepnote_cell_height": 161.5625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Problem: Mona Lisa not looking good:(\n",
    "\n",
    "Reason: Some pixel values are overflowing!\n",
    "\n",
    "Solution: cap pixel values to [0,255] interval\n",
    "\n",
    "But to do this, we need to first cast the image to uint16 ([0, 65535]), then cast it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00025-be17981a-6b52-4567-9ca1-08a9f390fff0",
    "deepnote_cell_height": 130.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.1875
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 2,
    "execution_start": 1660617228854,
    "source_hash": "9cc901cb"
   },
   "outputs": [],
   "source": [
    "image_16bit = np.array(image.astype(np.uint16))\n",
    "image_16bit.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-17dca896-0e47-4af0-abb8-496c6c04da2e",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Increasing brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-44c14649-6903-4950-9656-d171f4433850",
    "deepnote_cell_height": 486,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     376
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 636,
    "execution_start": 1660617231045,
    "source_hash": "897c8f5d"
   },
   "outputs": [],
   "source": [
    "image2 = np.clip(image_16bit+added, 0, 255).astype(np.uint8)\n",
    "idisp(image2, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-103bc662-9967-42d3-b5c2-94ec6a961007",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Changing contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_factor = 2\n",
    "image2 = np.clip(image_16bit*contrast_factor, 0, 255).astype(np.uint8)\n",
    "idisp(image2, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-83b01f83-3ea8-400e-8ac1-d87a88cbc9fc",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Negative Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00031-b0ce040b-122f-4fec-ac93-c0a5857bf6a9",
    "deepnote_cell_height": 486,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     376
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 684,
    "execution_start": 1660617280206,
    "source_hash": "f80df375"
   },
   "outputs": [],
   "source": [
    "image2 = 255-image\n",
    "idisp(image2, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-aba6d01b-3ad3-42ab-81dc-a03b1c9ae6a1",
    "deepnote_cell_height": 173.171875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Thresholding\n",
    "\n",
    "Create a mask based on whether the pixel values is a specific number. \n",
    "\n",
    "false (black) if x = Value\n",
    "\n",
    "true (white) if x != Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_background = iread_color('gs_background.png')\n",
    "image_greenscreen = iread_color('green_screen.png')\n",
    "idisp(image_greenscreen, height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00034-50ca310f-6984-4785-afba-4a603dac32d1",
    "deepnote_cell_height": 166.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1660623950574,
    "source_hash": "65e9ee60"
   },
   "outputs": [],
   "source": [
    "#what colour is the green pixel?\n",
    "image_greenscreen[200,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "allow_embed": false,
    "cell_id": "1842dea3b89a4d9a898dded34b4d201a",
    "deepnote_cell_height": 366,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     238
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 750,
    "execution_start": 1660624019589,
    "source_hash": "721f2a6c"
   },
   "outputs": [],
   "source": [
    "mask = np.alltrue(image_greenscreen == [0,252,0], axis=2)\n",
    "idisp(mask, height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "allow_embed": false,
    "cell_id": "6e5f4f7f3534499b992751538034fd86",
    "deepnote_cell_height": 474,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     238
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1357,
    "execution_start": 1660624714695,
    "source_hash": "8e2d2a58"
   },
   "outputs": [],
   "source": [
    "image_masked = image_greenscreen * mask[:, :, None]\n",
    "#np.broadcast_to(mask, image_greenscreen.shape)\n",
    "#mask3channel.shape\n",
    "\n",
    "# (background * mask) + (foreground * inverse mask)\n",
    "image_background = image_background * mask[:, :, None]\n",
    "image_foreground = image_greenscreen * np.invert(mask)[:, :, None]\n",
    "\n",
    "idisp(image_background + image_foreground, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-31960bee-e4a2-4979-bd39-b28678babada",
    "deepnote_cell_height": 100.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Flux Question 1\n",
    "Which task used diadic image operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-131a1d68-9283-4491-89cf-888da174a4bd",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-4fec7e1a-b5be-44b0-a1ea-8f3556202711",
    "deepnote_cell_height": 540,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     376
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 334,
    "execution_start": 1660625071354,
    "source_hash": "dd280cca"
   },
   "outputs": [],
   "source": [
    "kernel_size = 5 # Window size must be odd!\n",
    "sigmaX = 5\n",
    "sigmaY = 5\n",
    "blur = cv2.GaussianBlur(image,(kernel_size,kernel_size), sigmaX, sigmaY)\n",
    "idisp(blur, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00037-69217e99-90d3-489e-bf84-b1d629ec3fd9",
    "deepnote_cell_height": 100.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Flux Question 2\n",
    "What is the effect of increasing kernel size for Gaussian blur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-f4483401-76a7-4b12-a078-945258e6a234",
    "deepnote_cell_height": 108.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"18\">3. Feature Extraction</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-01bf9fcf-043d-4c85-9906-2200759a01f5",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00041-8ca76524-fa50-4877-aa33-407ac14b1a62",
    "deepnote_cell_height": 1143,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     267,
     267
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5291,
    "execution_start": 1660624828629,
    "source_hash": "95a2e9e7"
   },
   "outputs": [],
   "source": [
    "# input image\n",
    "image_chessboard_color = iread_color('chessboard.jpg')\n",
    "plt.imshow(image_chessboard_color)\n",
    "\n",
    "# Convert input img to 32bit, grayscale image\n",
    "image_chessboard = iread('chessboard.jpg')\n",
    "image_chessboard = np.float32(image_chessboard)\n",
    "\n",
    "# Harris corner detector\n",
    "out = cv2.cornerHarris(image_chessboard,2,3,0.04)\n",
    "\n",
    "# Threshold for Harris corner detector\n",
    "corner_threshold = 0.05\n",
    "\n",
    "circle_radius = 4\n",
    "circle_color = (255,0,0)\n",
    "circle_thickness = 0\n",
    "\n",
    "# Draw circles around the corners for better visibility \n",
    "for i in range(out.shape[0]):\n",
    "    for j in range(out.shape[1]):\n",
    "        if out[i,j]>corner_threshold*out.max():\n",
    "            cv2.circle(image_chessboard_color, (j,i), circle_radius, circle_color, circle_thickness)\n",
    "\n",
    "            \n",
    "#Display image\n",
    "plt.figure()\n",
    "plt.imshow(image_chessboard_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00042-ba140dc2-ead1-499e-8b5b-ed51289b1270",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Edge Detection and Line Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00043-8859ef2b-10e2-4e9d-b54c-464054361ac2",
    "deepnote_cell_height": 1233,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     232,
     232,
     232
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 693,
    "execution_start": 1660624833423,
    "source_hash": "26bccc3a"
   },
   "outputs": [],
   "source": [
    "# Read input img\n",
    "image_fed_sq_color = iread_color('empire_state.jpg')\n",
    "plt.imshow(image_fed_sq_color)\n",
    "\n",
    "# Canny Edge Detection\n",
    "#threshold1=first threshold for the hysteresis procedure.\n",
    "#threshold2=second threshold for the hysteresis procedure.\n",
    "edges = cv2.Canny(image=image_fed_sq_color, threshold1=100, threshold2=200)\n",
    "plt.imshow(edges)\n",
    "\n",
    "# Hough Transform for Line Detection\n",
    "#rho=Distance resolution of the accumulator in pixels.\n",
    "#theta=Angle resolution of the accumulator in radians.\n",
    "#hough_threshold = Accumulator threshold parameter. Only those lines are returned that get enough votes ( >threshold ).\n",
    "#minLineLength=Minimum line length. Line segments shorter than that are rejected.\n",
    "#maxLineGap=Maximum allowed gap between points on the same line to link them.\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=100, maxLineGap=10)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(image_fed_sq_color,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "plt.imshow(image_fed_sq_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-dc690dbb-47b4-4574-823f-2fc87ef1c0ea",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Feature Descriptors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00045-9ed8e269-d7e0-4e79-8fc3-046f65175675",
    "deepnote_cell_height": 508,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     213
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 236,
    "execution_start": 1660624834111,
    "source_hash": "2017a39d"
   },
   "outputs": [],
   "source": [
    "# Get input image\n",
    "pringles_original_color = iread_color('pringles_can.png')\n",
    "pringles_original_gray = iread('pringles_can.png')\n",
    "\n",
    "# Create SIFT Descriptor\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect SIFT Keypoints\n",
    "kp = sift.detect(pringles_original_gray,None)\n",
    "\n",
    "pringles_original_color=cv2.drawKeypoints(pringles_original_color, kp, pringles_original_color, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(pringles_original_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00046-8c7ff7a6-d8f8-4e42-bdc6-2791b6a4eda6",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00047-ed69492a-fe88-40f4-8ef7-7039987711ed",
    "deepnote_cell_height": 1383,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     332
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1046,
    "execution_start": 1660624928231,
    "source_hash": "a5cde376"
   },
   "outputs": [],
   "source": [
    "# Get input image\n",
    "input_img_str = 'pringles_can.png'\n",
    "pringles_color = iread_color(input_img_str)\n",
    "pringles_gray = iread(input_img_str)\n",
    "\n",
    "# Get Test Image\n",
    "test_img_str = 'pringles_test4.jpg'\n",
    "pringles_test_color = iread_color(test_img_str)\n",
    "pringles_test_gray = iread(test_img_str)\n",
    "\n",
    "# Create SIFT Descriptor\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect SIFT Keypoints\n",
    "kp1, des1 = sift.detectAndCompute(pringles_gray,None)\n",
    "kp2, des2 = sift.detectAndCompute(pringles_test_gray,None)\n",
    "\n",
    "# FLANN stands for Fast Library for Approximate Nearest Neighbors\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "ratio_test_threshold = 0.9\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < ratio_test_threshold*n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "#Now we set a condition that atleast 10 matches (defined by MIN_MATCH_COUNT) are to be there to find the object. Otherwise simply show a message saying not enough matches are present.\n",
    "MIN_MATCH_COUNT = 5\n",
    "\n",
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w = pringles_gray.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv2.perspectiveTransform(pts,M)\n",
    "    pringles_test_gray = cv2.polylines(pringles_test_gray,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "else:\n",
    "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None\n",
    "    \n",
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "img3 = cv2.drawMatches(pringles_color,kp1,pringles_test_color,kp2,good,None,**draw_params)\n",
    "idisp(img3, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00048-dde28aaa-3e74-403b-9ac6-5161638c6354",
    "deepnote_cell_height": 237.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Flux Question 3\n",
    "Test the system with test images pringles_test1.jpg to pringles_test4.jpg. \n",
    "\n",
    "What problems can you observe with keypoint matching based object detection?"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "68d363f4-48df-46b6-ac3d-60f254c36a63",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
